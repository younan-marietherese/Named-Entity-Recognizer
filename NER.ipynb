{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Named Entity Recognizer**\n",
        "\n",
        "Instructions:\n",
        "\n",
        "You can find a corpus, possibly tagged with Arabic Named Entities or create a dataset that contains a few sentences, manually label the named entities.\n",
        "\n",
        "1- Load your corpus to a Data Frame\n",
        "\n",
        "2- Apply the necessary preprocessing steps using regEx, tokenization and/or lemmatization, in case you created your own corpus.\n",
        "\n",
        "3- Develop your own NER. It could be rule-based, or you could build a predictive machine learning model for the task using the annotated corpus.\n",
        "\n",
        "4- Evaluate the results using accuracy, recall, etc. and analyze the results."
      ],
      "metadata": {
        "id": "mUtczc8VA0F5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Step 0: Install Farasa***"
      ],
      "metadata": {
        "id": "FI3yApSO21If"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "POpIz5LmqTuL",
        "outputId": "8873edaf-2a3a-4b25-fd0d-5921e5e96ebb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting farasapy\n",
            "  Downloading farasapy-0.0.14-py3-none-any.whl.metadata (8.9 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from farasapy) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from farasapy) (4.66.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->farasapy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->farasapy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->farasapy) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->farasapy) (2024.8.30)\n",
            "Downloading farasapy-0.0.14-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: farasapy\n",
            "Successfully installed farasapy-0.0.14\n"
          ]
        }
      ],
      "source": [
        "#install Java and Farasapy\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "!pip install farasapy\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "from farasa.segmenter import FarasaSegmenter\n",
        "from farasa.ner import FarasaNamedEntityRecognizer\n",
        "from farasa.stemmer import FarasaStemmer\n",
        "#initialize Farasa Segmenter and NER\n",
        "farasa_segmenter = FarasaSegmenter(interactive=True)\n",
        "farasa_ner = FarasaNamedEntityRecognizer(interactive=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YFcsXSGTqaid",
        "outputId": "5faea242-799d-4a6a-c263-17c8f7cc2a85"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py:1100: InsecureRequestWarning: Unverified HTTPS request is being made to host 'farasa-api.qcri.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100%|██████████| 241M/241M [03:06<00:00, 1.29MiB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[2024-09-19 13:52:41,701 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n",
            "[2024-09-19 13:52:47,924 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install Farasa in Step 0 to process Arabic text.\n",
        "To achieve advanced tokenization and lemmatization in Arabic, install the Farasa library."
      ],
      "metadata": {
        "id": "0Vk2kTO44vCS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Step 1: Create the dataset with sentences and manually labeled entities***"
      ],
      "metadata": {
        "id": "RrWQu_bi3Rrx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = {\n",
        "    'sentence': [\n",
        "        'زار البابا فرنسيس مدينة أبوظبي لتعزيز الحوار بين الأديان.',\n",
        "        'أعلن نادي برشلونة عن انتقال اللاعب البرتغالي كريستيانو رونالدو إلى صفوفه.',\n",
        "        'افتتحت شركة سامسونج معرضاً جديداً في مدينة دبي.',\n",
        "        'زار الرئيس الفرنسي إيمانويل ماكرون لبنان بعد انفجار مرفأ بيروت.',\n",
        "        'ألقى الشاعر نزار قباني قصيدة في مهرجان قرطاج الدولي.',\n",
        "        'تعاقدت وزارة الصحة المصرية مع منظمة اليونيسف لتحسين خدمات الصحة العامة.',\n",
        "        'تم اكتشاف تمثال جديد في منطقة الأهرامات في مصر.',\n",
        "        'عقدت قمة المناخ في العاصمة الدنماركية كوبنهاغن بمشاركة قادة العالم.',\n",
        "        'أعلنت جامعة القاهرة عن مؤتمرها السنوي حول الذكاء الاصطناعي.',\n",
        "        'وقعت دولة الإمارات اتفاقية تعاون اقتصادي مع الهند.'\n",
        "    ],\n",
        "    'entities': [\n",
        "        [('البابا فرنسيس', 'Person'), ('مدينة أبوظبي', 'Location')],\n",
        "        [('نادي برشلونة', 'Organization'), ('اللاعب البرتغالي', 'Position'), ('كريستيانو رونالدو', 'Person')],\n",
        "        [('شركة سامسونج', 'Organization'), ('مدينة دبي', 'Location')],\n",
        "        [('الرئيس الفرنسي', 'Position'), ('إيمانويل ماكرون', 'Person'), ('لبنان', 'Location'), ('مرفأ بيروت', 'Location')],\n",
        "        [('الشاعر نزار قباني', 'Person'), ('مهرجان قرطاج الدولي', 'Event')],\n",
        "        [('وزارة الصحة المصرية', 'Organization'), ('منظمة اليونيسف', 'Organization')],\n",
        "        [('منطقة الأهرامات', 'Location'), ('مصر', 'Location')],\n",
        "        [('قمة المناخ', 'Event'), ('العاصمة الدنماركية كوبنهاغن', 'Location')],\n",
        "        [('جامعة القاهرة', 'Organization'), ('مؤتمرها السنوي', 'Event')],\n",
        "        [('دولة الإمارات', 'Location'), ('الهند', 'Location')]\n",
        "    ]\n",
        "}"
      ],
      "metadata": {
        "id": "Yb4MDsKPrKE6"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create a DataFrame from the corpus\n",
        "df = pd.DataFrame(data)"
      ],
      "metadata": {
        "id": "50BSWgGErN-y"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#save data into a csv file\n",
        "df.to_csv('arabic_ner_corpus.csv', index=False, encoding='utf-8-sig')"
      ],
      "metadata": {
        "id": "aYhYpdKcrhOa"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1 involved the creation of an Arabic sentence dataset with manual entity annotations. For processing, this data is put into a pandas DataFrame."
      ],
      "metadata": {
        "id": "7pDSmivy4Kib"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Step 2: Apply Preprocessing Steps***"
      ],
      "metadata": {
        "id": "sP5MrASZ3kaG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "#initialize the Farasa Stemmer\n",
        "stemmer = FarasaStemmer()\n",
        "\n",
        "def preprocess_text(text):\n",
        "    #step A: RegEx Cleaning - Remove any non-Arabic letters, numbers, and special characters\n",
        "    text = re.sub(r'[^ا-ي\\s]', '', text)\n",
        "\n",
        "    #step B: Tokenization - Split text into words\n",
        "    tokens = text.split()\n",
        "\n",
        "    #step C: Stemming - Apply Farasa Stemmer to each token\n",
        "    stemmed_tokens = [stemmer.stem(token) for token in tokens]\n",
        "\n",
        "    #return the stemmed text\n",
        "    return \" \".join(stemmed_tokens)\n",
        "\n",
        "#apply the preprocessing function to the 'sentence' column\n",
        "df['processed_text'] = df['sentence'].apply(preprocess_text)\n",
        "\n",
        "#display the first few rows of the dataframe with the new processed text\n",
        "df.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "rtgY87yN4qLM",
        "outputId": "adaf04a9-c7ef-4449-8939-0954d19db214"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            sentence  \\\n",
              "0  زار البابا فرنسيس مدينة أبوظبي لتعزيز الحوار ب...   \n",
              "1  أعلن نادي برشلونة عن انتقال اللاعب البرتغالي ك...   \n",
              "2    افتتحت شركة سامسونج معرضاً جديداً في مدينة دبي.   \n",
              "3  زار الرئيس الفرنسي إيمانويل ماكرون لبنان بعد ا...   \n",
              "4  ألقى الشاعر نزار قباني قصيدة في مهرجان قرطاج ا...   \n",
              "\n",
              "                                            entities  \\\n",
              "0  [(البابا فرنسيس, Person), (مدينة أبوظبي, Locat...   \n",
              "1  [(نادي برشلونة, Organization), (اللاعب البرتغا...   \n",
              "2  [(شركة سامسونج, Organization), (مدينة دبي, Loc...   \n",
              "3  [(الرئيس الفرنسي, Position), (إيمانويل ماكرون,...   \n",
              "4  [(الشاعر نزار قباني, Person), (مهرجان قرطاج ال...   \n",
              "\n",
              "                                      processed_text  \n",
              "0     زار بابا فرنسيس مدينة وظبي تعزيز حوار بين ديان  \n",
              "1  علن نادي برشلونه عن انتقال لاعب برتغالي كريستي...  \n",
              "2          افتتح شركة سامسونج معرض جديد في مدينة دبي  \n",
              "3  زار ريس فرنسي يمانويل ماكر لبنان بعد انفجار مر...  \n",
              "4      لقى شاعر نزار قبان قصيدة في مهرجان قرطاج دولي  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-df80b04a-bfab-4182-b1df-9935c4b9e179\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>entities</th>\n",
              "      <th>processed_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>زار البابا فرنسيس مدينة أبوظبي لتعزيز الحوار ب...</td>\n",
              "      <td>[(البابا فرنسيس, Person), (مدينة أبوظبي, Locat...</td>\n",
              "      <td>زار بابا فرنسيس مدينة وظبي تعزيز حوار بين ديان</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>أعلن نادي برشلونة عن انتقال اللاعب البرتغالي ك...</td>\n",
              "      <td>[(نادي برشلونة, Organization), (اللاعب البرتغا...</td>\n",
              "      <td>علن نادي برشلونه عن انتقال لاعب برتغالي كريستي...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>افتتحت شركة سامسونج معرضاً جديداً في مدينة دبي.</td>\n",
              "      <td>[(شركة سامسونج, Organization), (مدينة دبي, Loc...</td>\n",
              "      <td>افتتح شركة سامسونج معرض جديد في مدينة دبي</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>زار الرئيس الفرنسي إيمانويل ماكرون لبنان بعد ا...</td>\n",
              "      <td>[(الرئيس الفرنسي, Position), (إيمانويل ماكرون,...</td>\n",
              "      <td>زار ريس فرنسي يمانويل ماكر لبنان بعد انفجار مر...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ألقى الشاعر نزار قباني قصيدة في مهرجان قرطاج ا...</td>\n",
              "      <td>[(الشاعر نزار قباني, Person), (مهرجان قرطاج ال...</td>\n",
              "      <td>لقى شاعر نزار قبان قصيدة في مهرجان قرطاج دولي</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-df80b04a-bfab-4182-b1df-9935c4b9e179')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-df80b04a-bfab-4182-b1df-9935c4b9e179 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-df80b04a-bfab-4182-b1df-9935c4b9e179');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-1485ccca-5eb3-46b0-b9f2-e8337568147e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1485ccca-5eb3-46b0-b9f2-e8337568147e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-1485ccca-5eb3-46b0-b9f2-e8337568147e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"sentence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"\\u0623\\u0639\\u0644\\u0646\\u062a \\u062c\\u0627\\u0645\\u0639\\u0629 \\u0627\\u0644\\u0642\\u0627\\u0647\\u0631\\u0629 \\u0639\\u0646 \\u0645\\u0624\\u062a\\u0645\\u0631\\u0647\\u0627 \\u0627\\u0644\\u0633\\u0646\\u0648\\u064a \\u062d\\u0648\\u0644 \\u0627\\u0644\\u0630\\u0643\\u0627\\u0621 \\u0627\\u0644\\u0627\\u0635\\u0637\\u0646\\u0627\\u0639\\u064a.\",\n          \"\\u0623\\u0639\\u0644\\u0646 \\u0646\\u0627\\u062f\\u064a \\u0628\\u0631\\u0634\\u0644\\u0648\\u0646\\u0629 \\u0639\\u0646 \\u0627\\u0646\\u062a\\u0642\\u0627\\u0644 \\u0627\\u0644\\u0644\\u0627\\u0639\\u0628 \\u0627\\u0644\\u0628\\u0631\\u062a\\u063a\\u0627\\u0644\\u064a \\u0643\\u0631\\u064a\\u0633\\u062a\\u064a\\u0627\\u0646\\u0648 \\u0631\\u0648\\u0646\\u0627\\u0644\\u062f\\u0648 \\u0625\\u0644\\u0649 \\u0635\\u0641\\u0648\\u0641\\u0647.\",\n          \"\\u062a\\u0639\\u0627\\u0642\\u062f\\u062a \\u0648\\u0632\\u0627\\u0631\\u0629 \\u0627\\u0644\\u0635\\u062d\\u0629 \\u0627\\u0644\\u0645\\u0635\\u0631\\u064a\\u0629 \\u0645\\u0639 \\u0645\\u0646\\u0638\\u0645\\u0629 \\u0627\\u0644\\u064a\\u0648\\u0646\\u064a\\u0633\\u0641 \\u0644\\u062a\\u062d\\u0633\\u064a\\u0646 \\u062e\\u062f\\u0645\\u0627\\u062a \\u0627\\u0644\\u0635\\u062d\\u0629 \\u0627\\u0644\\u0639\\u0627\\u0645\\u0629.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"entities\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"processed_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"\\u0639\\u0644\\u0646 \\u062c\\u0627\\u0645\\u0639\\u0629 \\u0642\\u0627\\u0647\\u0631\\u0629 \\u0639\\u0646 \\u0645\\u062a\\u0645\\u0631 \\u0633\\u0646\\u0648\\u064a \\u062d\\u0648\\u0644 \\u0630\\u0643\\u0627 \\u0627\\u0635\\u0637\\u0646\\u0627\\u0639\\u064a\",\n          \"\\u0639\\u0644\\u0646 \\u0646\\u0627\\u062f\\u064a \\u0628\\u0631\\u0634\\u0644\\u0648\\u0646\\u0647 \\u0639\\u0646 \\u0627\\u0646\\u062a\\u0642\\u0627\\u0644 \\u0644\\u0627\\u0639\\u0628 \\u0628\\u0631\\u062a\\u063a\\u0627\\u0644\\u064a \\u0643\\u0631\\u064a\\u0633\\u062a\\u064a\\u0627\\u0646\\u0648 \\u0631\\u0648\\u0646\\u0627\\u0644\\u062f\\u0648 \\u0644\\u0649 \\u0635\\u0641\",\n          \"\\u062a\\u0639\\u0627\\u0642\\u062f \\u0648\\u0632\\u0627\\u0631\\u0629 \\u0635\\u062d\\u0629 \\u0645\\u0635\\u0631\\u064a \\u0645\\u0639 \\u0645\\u0646\\u0638\\u0645\\u0629 \\u064a\\u0648\\u0646\\u064a\\u0633\\u0641 \\u062a\\u062d\\u0633\\u064a\\u0646 \\u062e\\u062f\\u0645\\u0629 \\u0635\\u062d\\u0629 \\u0639\\u0627\\u0645\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#save the new data into a csv file\n",
        "df.to_csv('processed_arabic_ner_corpus_new.csv', index=False,encoding='utf-8-sig' )"
      ],
      "metadata": {
        "id": "zaxdHQIYsCix"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Arabic text undergone three main preprocessing processes in step 2:\n",
        "\n",
        "It was cleaned using regular expressions to eliminate non-Arabic letters and special characters;\n",
        "\n",
        "It was tokenized into individual words;\n",
        "\n",
        "and finally, each token was reduced to its root form using the Farasa Stemmer.\n",
        "\n",
        "Each phrase in the processed text is then converted to its stemmed form and added to a new column in the DataFrame.\n",
        "\n",
        "Simplified versions of the original sentences with words reduced to their stems are displayed in the processed text.\n"
      ],
      "metadata": {
        "id": "I2UVTvmk4OPq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Step3: Develop Your Own NER (Rule-Based)***"
      ],
      "metadata": {
        "id": "WZbmdKEB31_C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def own_rule_based_ner(tokens):\n",
        "    #lets define lists of keywords for each entity type\n",
        "    person_titles = ['البابا', 'الرئيس', 'الشاعر', 'إيمانويل', 'كريستيانو', 'نزار']\n",
        "    location_keywords = ['مدينة', 'العاصمة', 'دولة', 'لبنان', 'مصر', 'الهند', 'كوبنهاغن', 'أبوظبي', 'دبي', 'باريس', 'بيروت']\n",
        "    organization_keywords = ['شركة', 'جامعة', 'نادي', 'منظمة', 'وزارة', 'برشلونة', 'سامسونج', 'يونيسف', 'هارفارد', 'القاهرة']\n",
        "    known_organizations = ['نادي برشلونة', 'شركة سامسونج', 'جامعة القاهرة']  #lets add multi-word organizations\n",
        "\n",
        "    entities = []\n",
        "\n",
        "    #iterate through tokens and identify entities\n",
        "    i = 0\n",
        "    while i < len(tokens):\n",
        "        token = tokens[i]\n",
        "        found_entity = False\n",
        "\n",
        "        #check for known multi-word organizations first\n",
        "        for org in known_organizations:\n",
        "            org_tokens = org.split()\n",
        "            if tokens[i:i + len(org_tokens)] == org_tokens:\n",
        "                entities.extend([(t, 'Organization') for t in org_tokens])\n",
        "                i += len(org_tokens)\n",
        "                found_entity = True\n",
        "                break\n",
        "\n",
        "        if found_entity:\n",
        "            continue\n",
        "\n",
        "        #check for person titles\n",
        "        if any(title in token for title in person_titles):\n",
        "            entities.append((token, 'Person'))\n",
        "        #check for keywords indicating an organization\n",
        "        elif any(token.startswith(keyword) for keyword in organization_keywords):\n",
        "            entities.append((token, 'Organization'))\n",
        "        #check for location indicators\n",
        "        elif token in location_keywords:\n",
        "            entities.append((token, 'Location'))\n",
        "        else:\n",
        "            entities.append((token, 'O'))\n",
        "\n",
        "        i += 1  #move to the next token\n",
        "\n",
        "    return entities\n",
        "\n",
        "#apply the rule-based NER to tokenized sentences\n",
        "df['tokens'] = df['sentence'].apply(lambda x: x.split())  #tokenize sentences\n",
        "df['predicted_entities'] = df['tokens'].apply(own_rule_based_ner)\n",
        "\n",
        "#align labels with entities\n",
        "def align_labels_with_entities(tokens, entities):\n",
        "    labels = ['O'] * len(tokens)  #initialize labels as 'O'\n",
        "\n",
        "    for i, (token, label) in enumerate(entities):\n",
        "        labels[i] = label\n",
        "\n",
        "    return labels\n",
        "\n",
        "#create labels based on the predictions\n",
        "df['labels'] = df.apply(lambda row: align_labels_with_entities(row['tokens'], row['predicted_entities']), axis=1)\n",
        "\n",
        "#display the DataFrame with predictions and labels\n",
        "print(df[['tokens', 'predicted_entities', 'labels']].head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jFMYRiqc8EYY",
        "outputId": "2b735813-21ca-4be8-99b6-205588b245b5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                              tokens  \\\n",
            "0  [زار, البابا, فرنسيس, مدينة, أبوظبي, لتعزيز, ا...   \n",
            "1  [أعلن, نادي, برشلونة, عن, انتقال, اللاعب, البر...   \n",
            "2  [افتتحت, شركة, سامسونج, معرضاً, جديداً, في, مد...   \n",
            "3  [زار, الرئيس, الفرنسي, إيمانويل, ماكرون, لبنان...   \n",
            "4  [ألقى, الشاعر, نزار, قباني, قصيدة, في, مهرجان,...   \n",
            "\n",
            "                                  predicted_entities  \\\n",
            "0  [(زار, O), (البابا, Person), (فرنسيس, O), (مدي...   \n",
            "1  [(أعلن, O), (نادي, Organization), (برشلونة, Or...   \n",
            "2  [(افتتحت, O), (شركة, Organization), (سامسونج, ...   \n",
            "3  [(زار, O), (الرئيس, Person), (الفرنسي, O), (إي...   \n",
            "4  [(ألقى, O), (الشاعر, Person), (نزار, Person), ...   \n",
            "\n",
            "                                              labels  \n",
            "0     [O, Person, O, Location, Location, O, O, O, O]  \n",
            "1  [O, Organization, Organization, O, O, O, O, Pe...  \n",
            "2  [O, Organization, Organization, O, O, O, Locat...  \n",
            "3    [O, Person, O, Person, O, Location, O, O, O, O]  \n",
            "4              [O, Person, Person, O, O, O, O, O, O]  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3: The tokenized text is iterated through by the rule-based NER function, which uses predefined keywords for persons, locations, and organizations to identify entities.\n",
        "\n",
        "The code creates a structured representation for additional assessment by aligning the labels with the tokens after predicting the entities.\n",
        "\n",
        "Results:\n",
        "\n",
        "The findings demonstrate the model's capacity to recognize individuals and organizations by displaying the tokenized sentences with the expected entities and the labels that correspond to them.\n",
        "\n",
        "Although certain entities were accurately categorized, a large number of tokens are still marked as \"O,\" suggesting that named entity recognition still needs work.\n",
        "\n"
      ],
      "metadata": {
        "id": "cv4bqlYS4SRE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Step 4: Evaluate the Results***"
      ],
      "metadata": {
        "id": "XeVaP01h3-rt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "#lets create a function to align true labels with all tokens in the sentence\n",
        "def align_true_labels_with_tokens(tokens, entities):\n",
        "    labels = ['O'] * len(tokens)  #initialize all tokens with 'O'\n",
        "\n",
        "    for entity, label in entities:\n",
        "        entity_tokens = entity.split()\n",
        "        for i in range(len(tokens) - len(entity_tokens) + 1):\n",
        "            if tokens[i:i + len(entity_tokens)] == entity_tokens:\n",
        "                for j in range(len(entity_tokens)):\n",
        "                    labels[i + j] = label\n",
        "                break\n",
        "    return labels\n",
        "\n",
        "#create aligned true labels for each sentence\n",
        "df['aligned_true_labels'] = df.apply(lambda row: align_true_labels_with_tokens(row['tokens'], row['entities']), axis=1)\n",
        "\n",
        "#flatten a list of lists into a single list\n",
        "def flatten_lists(lists):\n",
        "    return [item for sublist in lists for item in sublist]\n",
        "\n",
        "#flatten the lists of aligned true labels and predicted labels\n",
        "true_labels = flatten_lists(df['aligned_true_labels'])\n",
        "predicted_labels = flatten_lists(df['labels'])\n",
        "\n",
        "#generate the classification report\n",
        "report = classification_report(true_labels, predicted_labels, labels=['Person', 'Organization', 'Location', 'O'], zero_division=0)\n",
        "\n",
        "print(report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fYqlO4Fn9X-N",
        "outputId": "0f0a56bc-f985-4240-afdd-3d77d9ca8e0e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Person       0.83      0.56      0.67         9\n",
            "Organization       1.00      0.73      0.84        11\n",
            "    Location       0.86      0.60      0.71        10\n",
            "           O       0.75      0.98      0.85        56\n",
            "\n",
            "   micro avg       0.79      0.86      0.82        86\n",
            "   macro avg       0.86      0.72      0.77        86\n",
            "weighted avg       0.81      0.86      0.81        86\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In step 4, we used measures like precision, recall, and F1-score to assess how well the rule-based NER model performed. This stage gives us an understanding of how well the model matches the ground truth in terms of entity identification.\n",
        "\n",
        "Results:\n",
        "\n",
        "The model exhibits low recall for \"Person\" (0.56) and \"Location\" (0.60), but good precision, particularly for \"Organization\" entities (1.00).\n",
        "\n",
        "The model does very well overall, but there is still space for improvement, especially in detecting \"Person\" and \"Location\" entities, as indicated by the weighted F1-score of 0.81.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Wj-Ikygc4V-R"
      }
    }
  ]
}
